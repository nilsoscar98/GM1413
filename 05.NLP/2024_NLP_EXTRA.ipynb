{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e235dbc4-c8cd-47a5-8a0f-810090028d7f",
   "metadata": {},
   "source": [
    "# <b><u>RUN THIS ON YOUR OWN MACHINE NOT OUR SERVERS!</u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6b48bc-f4cb-4909-832b-5ca758774130",
   "metadata": {},
   "source": [
    "# <b><u>Not mandatory material!</u></b>\n",
    "Just included for those who want to move on to Generative AI or get some inspiration.\n",
    "\n",
    "### <u>If you want to apply Generative AI, go down to the bottom and see Ollama and running a request to a LLM on your local machine.</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d20eb1-49cf-404f-aa3c-7ec2b22fc675",
   "metadata": {},
   "source": [
    "# Advanced Natural Language Processing (NLP)\n",
    "\n",
    "This notebook explores more advanced NLP concepts that go beyond the basics of dictionary-based sentiment analysis. These techniques will allow for deeper linguistic analysis and more complex tasks such as Named Entity Recognition (NER), Part-of-Speech (POS) tagging, and working with pre-trained transformer models.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Tokenization\n",
    "\n",
    "### What is Tokenization?\n",
    "Tokenization is the process of splitting text into individual units called **tokens**. These tokens are often words, but they can also be punctuation marks or other meaningful units in a text. Tokenization is a crucial step in many NLP pipelines, as it forms the basis for subsequent processing tasks.\n",
    "\n",
    "### Example: Tokenizing Text with SpaCy\n",
    "We will use `spaCy` to demonstrate how to tokenize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac85952c-70b4-4ff7-994a-bc6168c96249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you encounter an issue related to spaCy, particularly one involving missing data or models, \n",
    "# you might need to download the English model explicitly. To do this, uncomment and run the following command:\n",
    "# !python -m spacy download en_core_web_md !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb73dab-de4c-4277-9e46-fe019e85505b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xappvi/miniconda3/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_md' (3.6.0) was trained with spaCy v3.6.0 and may not be 100% compatible with the current version (3.7.6). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "company\n",
      "'s\n",
      "revenue\n",
      "grew\n",
      "by\n",
      "15\n",
      "%\n",
      ",\n",
      "despite\n",
      "the\n",
      "challenging\n",
      "economic\n",
      "conditions\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Sample text\n",
    "text = \"The company's revenue grew by 15%, despite the challenging economic conditions.\"\n",
    "\n",
    "# Tokenizing the text\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044a357-7608-4958-9c76-2ff86831abe2",
   "metadata": {},
   "source": [
    "# 2. Part-of-Speech (POS) Tagging\n",
    "### What is POS Tagging?\n",
    "Part-of-Speech tagging is the process of labeling words in a text with their grammatical role, such as noun, verb, adjective, etc. POS tagging helps to understand the structure of sentences, which can be particularly useful for tasks like extracting specific financial information from texts.\n",
    "\n",
    "### Example: POS Tagging with SpaCy\n",
    "We will now use spaCy to tag each word in a text with its part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ada64d9-a067-41bf-83fb-b0421af8cf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The - DET\n",
      "company - NOUN\n",
      "'s - PART\n",
      "revenue - NOUN\n",
      "grew - VERB\n",
      "by - ADP\n",
      "15 - NUM\n",
      "% - NOUN\n",
      ", - PUNCT\n",
      "despite - SCONJ\n",
      "the - DET\n",
      "challenging - ADJ\n",
      "economic - ADJ\n",
      "conditions - NOUN\n",
      ". - PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Perform POS tagging\n",
    "for token in doc:\n",
    "    print(f\"{token.text} - {token.pos_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f7bf3-7b91-4c60-ad48-b722c828bd14",
   "metadata": {},
   "source": [
    "This example will output the grammatical category of each word in the sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3274e-50f7-4ed3-bb4b-36a715269f9d",
   "metadata": {},
   "source": [
    "# 3. Named Entity Recognition (NER)\n",
    "### What is Named Entity Recognition (NER)?\n",
    "NER is a process that identifies and classifies named entities in text, such as people, organizations, locations, monetary values, and dates. In finance, NER is useful for extracting important entities like company names, product names, and financial terms.\n",
    "\n",
    "### Example: NER with SpaCy\n",
    "Here’s how to identify named entities in a text using spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0ddcbe-ee02-499f-9a64-9e3941eab81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15% - PERCENT\n"
     ]
    }
   ],
   "source": [
    "# Perform Named Entity Recognition (NER)\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} - {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c44c4-14fe-45b8-84d8-de25e711ccad",
   "metadata": {},
   "source": [
    "In this example, spaCy will recognize entities like \"company,\" \"revenue,\" \"15%\" and classify them into categories like ORG (organization), MONEY, or PERCENT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66630393-d362-41d3-9630-17fd837bcc13",
   "metadata": {},
   "source": [
    "# 4. Sentiment Analysis Using Pre-trained Models\n",
    "### What Are Pre-trained Sentiment Models?\n",
    "Pre-trained models are machine learning models that have been trained on large datasets and can be fine-tuned for specific tasks, such as sentiment analysis. In this section, we will explore how to use a pre-trained sentiment model for more complex text analysis.\n",
    "\n",
    "### Using transformers for Sentiment Analysis\n",
    "We will use a pre-trained transformer model from Hugging Face’s transformers library to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c044c5-73eb-4a32-9810-8a8d1efb4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3764f699-9161-45d9-aaf1-414df76cf357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Analyze the sentiment of a financial text\n",
    "result = sentiment_pipeline(\"The company's profits have surged, but the rising debt is concerning.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2e26a-ddac-43a7-bdcb-81e66206d8b7",
   "metadata": {},
   "source": [
    "This will return a sentiment score with a label like \"POSITIVE\" or \"NEGATIVE,\" along with a confidence score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1d066-0c01-4f84-98c2-0f91f975c8ee",
   "metadata": {},
   "source": [
    "# 5. Word Embeddings and Similarity\n",
    "### What Are Word Embeddings?\n",
    "Word embeddings are dense vector representations of words, where words with similar meanings are located close to each other in vector space. Word embeddings are more powerful than simple dictionary-based methods because they capture the meaning of words in context.\n",
    "\n",
    "### Example: Finding Word Similarity with Word Vectors\n",
    "SpaCy’s en_core_web_md and en_core_web_lg models include pre-trained word vectors, which allow us to measure how similar two words are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c3a444-32ad-4eb9-84e6-4ba87bf810c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'profit' and 'gain': 0.35158402153765206\n"
     ]
    }
   ],
   "source": [
    "# Example of word similarity using word vectors\n",
    "token1 = nlp(\"profit\")\n",
    "token2 = nlp(\"gain\")\n",
    "\n",
    "similarity = token1.similarity(token2)\n",
    "print(f\"Similarity between 'profit' and 'gain': {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d252abf8-abf5-4322-909b-b79b12d4f843",
   "metadata": {},
   "source": [
    "This shows how semantically related the words \"profit\" and \"gain\" are, based on their positions in the word embedding space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a4d3a-aea3-4dd4-9f37-dbf1fd786078",
   "metadata": {},
   "source": [
    "# 6. Advanced Text Preprocessing: Custom Stop Words and Domain-Specific Vocabulary\n",
    "### Using Custom Stop Words\n",
    "In some cases, we may need to remove additional words that are not part of default stop word lists but are specific to the domain we are analyzing. For example, terms like \"report\" or \"figure\" may be common in financial reports but are not necessarily informative for sentiment analysis.\n",
    "\n",
    "### Example: Adding Custom Stop Words to SpaCy\n",
    "We will add some domain-specific stop words to the existing list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30fc88c-083f-4546-8916-7854ca5a7a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company revenue grew 15 % , despite challenging economic conditions .\n"
     ]
    }
   ],
   "source": [
    "# Add custom stop words\n",
    "custom_stop_words = [\"company\", \"report\", \"figure\"]\n",
    "for word in custom_stop_words:\n",
    "    nlp.Defaults.stop_words.add(word)\n",
    "\n",
    "# Remove custom stop words from text\n",
    "cleaned_text = ' '.join([token.text for token in doc if not token.is_stop])\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c156344-5776-495c-a275-7b74c4612c2c",
   "metadata": {},
   "source": [
    "This allows us to tailor the preprocessing step to our specific domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670c14d-4ea6-4f1c-a367-b02f5e53c144",
   "metadata": {},
   "source": [
    "# 7. Transformers and Transfer Learning in NLP (Optional)\n",
    "### What Are Transformers?\n",
    "Transformers are advanced neural network architectures that power state-of-the-art NLP models like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer). These models can be fine-tuned for a wide variety of tasks, including sentiment analysis, summarization, and question answering.\n",
    "\n",
    "### Example: Loading a Transformer Model for Text Classification\n",
    "Here’s an optional introduction to using transformers for NLP tasks, leveraging the Hugging Face library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cfb74b-a41a-4022-ae92-e6e20a89cd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ed91c96f0c47d0b37202f4f10a4af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb22f813c8b84096a7d7b2226b9fe15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x11c4e0ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xappvi/miniconda3/lib/python3.10/site-packages/tqdm/std.py\", line 1147, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a text classification model (e.g., sentiment or other task)\n",
    "classifier = pipeline('text-classification', model='distilbert-base-uncased')\n",
    "\n",
    "# Apply the classifier to text\n",
    "result = classifier(\"The stock market crashed, causing widespread panic among investors.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b588d5-a9e2-4427-8048-16bde09f66b7",
   "metadata": {},
   "source": [
    "This model is more advanced than simple dictionary methods and can provide more context-aware results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734aac2d-7b9d-4ee0-8a15-adb017b289fa",
   "metadata": {},
   "source": [
    "# Conclusion: Next Steps in NLP\n",
    "In this advanced notebook, we have explored more complex NLP techniques, including tokenization, POS tagging, Named Entity Recognition, and the use of pre-trained models for sentiment analysis. These tools can provide a deeper understanding of textual data, which is especially useful for advanced financial analysis.\n",
    "\n",
    "### The next steps could include:\n",
    "Applying transformers to more complex financial texts for sentiment and trend analysis.\n",
    "Exploring deeper linguistic features like syntax and dependency parsing.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation of Topics:\n",
    "- **Tokenization**: Introduces the fundamental task of breaking down text into individual tokens, which is the first step in many NLP pipelines.\n",
    "- **POS Tagging**: Helps identify the grammatical role of words in a sentence, useful for extracting structured information from text.\n",
    "- **Named Entity Recognition (NER)**: Extracts entities such as organizations, dates, and monetary values from text, which is particularly useful in finance.\n",
    "- **Pre-trained Sentiment Models**: Demonstrates how to use advanced models for sentiment analysis, beyond simple dictionary-based methods.\n",
    "- **Word Embeddings and Similarity**: Shows how words can be represented in vector space, allowing for the comparison of word meanings.\n",
    "- **Advanced Text Preprocessing**: Adds the ability to customize stop words, particularly for domain-specific vocabulary in finance.\n",
    "- **Transformers and Transfer Learning**: Introduces the most advanced NLP techniques, showing how state-of-the-art models can be applied to financial text analysis.\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294415b-2386-4d82-89b1-8f877f3aa2c1",
   "metadata": {},
   "source": [
    "# Understanding Ollama and Open Source Models\n",
    "\n",
    "## What is Ollama?\n",
    "\n",
    "Ollama is a platform that simplifies the use of large language models (LLMs) by providing easy access to various models, including open-source ones. It allows users to run language models locally or on the cloud, often making it more accessible for developers, researchers, and businesses to integrate powerful natural language processing models into their applications.\n",
    "\n",
    "Ollama's main goal is to make working with language models seamless, allowing users to generate text, analyze documents, or answer questions using sophisticated AI models with just a few simple commands.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Open Source?\n",
    "\n",
    "**Open source** refers to software whose source code is freely available for anyone to use, modify, and distribute. This philosophy promotes collaboration, transparency, and community-driven development. Many open-source projects are built and maintained by communities of developers from around the world.\n",
    "\n",
    "---\n",
    "\n",
    "## What Are Open Source Models?\n",
    "\n",
    "**Open source models** are machine learning or language models that are freely available for public use, modification, and distribution. These models are often shared on platforms like GitHub or Hugging Face, enabling anyone to integrate them into their own projects.\n",
    "\n",
    "Open source models can be trained on large datasets and can be used for various natural language processing (NLP) tasks, such as translation, summarization, and sentiment analysis. The beauty of open-source models is that they are not controlled by any single entity, and anyone can contribute to improving their performance or tailoring them for specific tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## The Meta LLaMA 3.1 Model\n",
    "\n",
    "**LLaMA 3.1** is the latest version of the **Large Language Model** developed by Meta (formerly Facebook). It is designed to be smaller and more efficient than some of the other massive language models like GPT-4, while still delivering high-quality language understanding and generation capabilities.\n",
    "\n",
    "Meta's LLaMA models are part of a broader push to make cutting-edge NLP technology more accessible, providing strong performance across tasks like language generation, summarization, and text classification, with fewer computational resources.\n",
    "\n",
    "Key features of LLaMA 3.1:\n",
    "- **Scalability**: Smaller and more efficient compared to other large models.\n",
    "- **Performance**: Strong language understanding and generation abilities, even for tasks that require deep contextual knowledge.\n",
    "- **Open-Source**: LLaMA models are often shared openly, encouraging researchers and developers to use and improve them.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Install Ollama and Run It Locally\n",
    "\n",
    "To use Ollama with models like **LLaMA 3.1**, you need to install it on your system. Here's a quick guide on how to install and run Ollama.\n",
    "\n",
    "### Step 1: Install Ollama\n",
    "Go to:\n",
    "<url>https://ollama.com/</url>\n",
    "\n",
    "### Step 3: Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4f055-3f28-4f07-9fc6-badc3c53e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull llama3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2767a01-abfd-4c0c-a7da-0d3f29cbda11",
   "metadata": {},
   "source": [
    "This command will download and install the LLaMA 3.1 model, ready for use.\n",
    "\n",
    "### Step 3: Running a Model with Ollama\n",
    "Once you have a model installed, you can run it locally by sending text prompts. Here's an example of how to analyze the sentiment of a dummy earnings call text using LLaMA 3.1.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8721f-8168-4c68-981e-582d8380fe8b",
   "metadata": {},
   "source": [
    "# Explanation of the Process\n",
    "## PromptTemplate:\n",
    "A prompt template is constructed to analyze the sentiment of the earnings call transcript. The template guides the model to read the transcript carefully and provide a sentiment analysis, listing the positive and negative aspects of the text. The response is structured in JSON format, ensuring easy parsing of the results.\n",
    "\n",
    "## Ollama Model:\n",
    "The Ollama class is used to initialize and run the language model, specifically loading Meta's LLaMA 3.1 model. This model is designed to handle various language processing tasks, including sentiment analysis, by interpreting the provided text based on the prompt instructions.\n",
    "\n",
    "## LLMChain:\n",
    "An LLMChain is set up to integrate the Ollama model with the custom PromptTemplate. The chain takes the prompt and runs it through the LLaMA model, ensuring a streamlined interaction between the input (the earnings call text) and the model’s response. The JsonOutputParser is included to ensure that the model’s response is returned in a valid and structured JSON format.\n",
    "\n",
    "## Running the Chain:\n",
    "Once the chain is created, it is executed using the earnings call text as input. The result is processed by the JSON output parser, extracting the positive and negative sentiment aspects, along with the overall sentiment summary. The final result is displayed as a JSON object for easy interpretation and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ab3cbf-968a-44c4-aebb-ca05bb59e94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the sentiment analysis in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"positive_aspects\": [\n",
      "    \"exceptional quarterly performance\",\n",
      "    \"strong revenue growth\",\n",
      "    \"increased profit margins\",\n",
      "    \"future opportunities\"\n",
      "  ],\n",
      "  \"negative_aspects\": [\n",
      "    \"rising operational costs\",\n",
      "    \"external market pressures\",\n",
      "    \"short-term hurdles\"\n",
      "  ],\n",
      "  \"summary\": \"The overall sentiment is cautiously optimistic, with a focus on the company's strong performance and future potential, while also acknowledging some challenges.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Dummy earnings call text\n",
    "earnings_call_text = \"\"\"\n",
    "The company's quarterly performance has been exceptional, with strong revenue growth and increased profit margins.\n",
    "However, rising operational costs and external market pressures have posed challenges.\n",
    "Our leadership remains confident about future opportunities despite these short-term hurdles.\n",
    "\"\"\"\n",
    "\n",
    "# Define the prompt for Ollama\n",
    "ollama_sentiment_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "        <|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "        You are an expert sentiment analysis model. Your task is to analyze the sentiment of the following earnings call transcript.\n",
    "\n",
    "        ### Instructions:\n",
    "\n",
    "        1. **Understand the Earnings Call:**\n",
    "            - Read the transcript carefully.\n",
    "            - Identify the positive and negative sentiment conveyed in the text.\n",
    "\n",
    "        2. **Provide the Sentiment Analysis:**\n",
    "            - List the positive aspects of the text.\n",
    "            - List the negative aspects of the text.\n",
    "            - Provide an overall sentiment summary based on the analysis.\n",
    "\n",
    "        The earnings call transcript is:\n",
    "        \"{earnings_call_text}\"\n",
    "\n",
    "        Please provide a sentiment analysis, specifying the positive and negative aspects of the text. Return your analysis in JSON format, like this:\n",
    "        \"positive_aspects\": [\"positive aspect 1\", \"positive aspect 2\"],\n",
    "        \"negative_aspects\": [\"negative aspect 1\", \"negative aspect 2\"],\n",
    "        \"summary\": \"Overall sentiment summary\"\n",
    "\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"earnings_call_text\"],\n",
    ")\n",
    "\n",
    "# Create the Ollama model\n",
    "llm = Ollama(model=\"llama3.1\", temperature=0)\n",
    "# Or if you would like to use ChatGPT\n",
    "# llm = OpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Create the chain (no output parser needed)\n",
    "ollama_sentiment_chain = LLMChain(\n",
    "    prompt=ollama_sentiment_prompt,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Run the chain with the earnings call text, result is a string\n",
    "sentiment_analysis_result = ollama_sentiment_chain.run(earnings_call_text=earnings_call_text)\n",
    "\n",
    "# Print the result as a string\n",
    "print(sentiment_analysis_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450dbc0-1ed0-4053-b687-34f5d0bbd04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
